{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(my_list, n):\n",
    "    final = [my_list[i * n:(i + 1) * n] for i in range((len(my_list) + n - 1) // n )]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = joblib.load(\"imbang/imbang_data.dt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.8905840508775098\n",
      "0.11 0.9018143162007496\n",
      "0.21000000000000002 0.9051113210952678\n",
      "0.31000000000000005 0.90619283977619\n",
      "0.41000000000000003 0.9071712656736068\n",
      "0.51 0.9079956894263539\n",
      "0.6100000000000001 0.9079955832545892\n",
      "0.7100000000000001 0.9082015033921879\n",
      "0.81 0.908047129646342\n",
      "0.91 0.9088715003132067\n",
      "1.01 0.9090261925743468\n",
      "1.11 0.9086655270897257\n",
      "1.2100000000000002 0.9084594476944801\n",
      "1.31 0.90840795438861\n",
      "1.4100000000000001 0.9084596600380095\n",
      "1.51 0.9081504347733764\n",
      "1.61 0.9085110471721152\n",
      "1.7100000000000002 0.908201981165129\n",
      "1.81 0.9076871542781912\n",
      "1.9100000000000001 0.9074812341405927\n",
      "2.01 0.9074811810547105\n",
      "2.11 0.9072238206971239\n",
      "2.21 0.907172221219489\n",
      "2.31 0.9073267542229819\n",
      "2.41 0.9076359794876152\n",
      "2.51 0.9074299531782518\n",
      "2.61 0.9071722743053712\n",
      "2.71 0.9065539299478695\n",
      "2.81 0.9066055294255045\n",
      "2.91 0.9066570758172572\n",
      "3.01 0.9064509964220117\n",
      "3.11 0.9062965165044009\n",
      "3.21 0.9057813180162869\n",
      "3.31 0.9059873974115324\n",
      "3.41 0.9056782783186639\n",
      "3.51 0.9050087060847039\n",
      "3.61 0.9049057725588456\n",
      "3.71 0.9049573189505983\n",
      "3.81 0.9044420142907196\n",
      "3.91 0.9041328421119689\n",
      "4.01 0.904029802414346\n",
      "4.11 0.9038751632390882\n",
      "4.21 0.9036174312803255\n",
      "4.31 0.9034115111427268\n",
      "4.41 0.9031024451357407\n",
      "4.51 0.9028963126546128\n",
      "4.61 0.9024844192935332\n",
      "4.71 0.9020723135889241\n",
      "4.8100000000000005 0.9021238068947944\n",
      "4.91 0.9019177274995489\n",
      "5.01 0.9019177805854313\n",
      "\n",
      "0.01 0.8905840508775098\n",
      "0.11 0.9018143162007496\n",
      "0.21000000000000002 0.9051113210952678\n",
      "0.31000000000000005 0.90619283977619\n",
      "0.41000000000000003 0.9071712656736068\n",
      "0.51 0.9079956894263539\n",
      "0.6100000000000001 0.9079955832545892\n",
      "0.7100000000000001 0.9082015033921879\n",
      "0.81 0.908047129646342\n",
      "0.91 0.9088715003132067\n",
      "1.01 0.9090261925743468\n",
      "1.11 0.9086655270897257\n",
      "1.2100000000000002 0.9084594476944801\n",
      "1.31 0.90840795438861\n",
      "1.4100000000000001 0.9084596600380095\n",
      "1.51 0.9081504347733764\n",
      "1.61 0.9085110471721152\n",
      "1.7100000000000002 0.908201981165129\n",
      "1.81 0.9076871542781912\n",
      "1.9100000000000001 0.9074812341405927\n",
      "2.01 0.9074811810547105\n",
      "2.11 0.9072238206971239\n",
      "2.21 0.907172221219489\n",
      "2.31 0.9073267542229819\n",
      "2.41 0.9076359794876152\n",
      "2.51 0.9074299531782518\n",
      "2.61 0.9071722743053712\n",
      "2.71 0.9065539299478695\n",
      "2.81 0.9066055294255045\n",
      "2.91 0.9066570758172572\n",
      "3.01 0.9064509964220117\n",
      "3.11 0.9062965165044009\n",
      "3.21 0.9057813180162869\n",
      "3.31 0.9059873974115324\n",
      "3.41 0.9056782783186639\n",
      "3.51 0.9050087060847039\n",
      "3.61 0.9049057725588456\n",
      "3.71 0.9049573189505983\n",
      "3.81 0.9044420142907196\n",
      "3.91 0.9041328421119689\n",
      "4.01 0.904029802414346\n",
      "4.11 0.9038751632390882\n",
      "4.21 0.9036174312803255\n",
      "4.31 0.9034115111427268\n",
      "4.41 0.9031024451357407\n",
      "4.51 0.9028963126546128\n",
      "4.61 0.9024844192935332\n",
      "4.71 0.9020723135889241\n",
      "4.8100000000000005 0.9021238068947944\n",
      "4.91 0.9019177274995489\n",
      "5.01 0.9019177805854313\n",
      "alpha : 1.01\n"
     ]
    }
   ],
   "source": [
    "accc = list()\n",
    "list_alpha = np.arange(0.01, 5+0.1, 0.1)\n",
    "for alp in list_alpha:\n",
    "    lis_sc = list()\n",
    "    for i in range(10):\n",
    "        X = md[\"model_tf_idf\"][i][\"train\"]#.toarray()\n",
    "        Y = np.array(md[\"model_tf_idf\"][i][\"y_train\"])\n",
    "        clf_pf = MultinomialNB(alpha = alp)\n",
    "        for batch in batches(np.arange(X.shape[0]), 1000):\n",
    "            clf_pf.partial_fit(X[batch].A, Y[batch], np.unique(Y))\n",
    "#             clf_pf.fit(X, Y)\n",
    "        sc = clf_pf.score(md[\"model_tf_idf\"][i][\"test\"].A, np.array(md[\"model_tf_idf\"][i][\"y_test\"]))\n",
    "        lis_sc.append(sc)\n",
    "    accc.append(sum(lis_sc)/len(lis_sc))\n",
    "    print(alp, sum(lis_sc)/len(lis_sc))\n",
    "print(\"\")\n",
    "for i, j in zip(list_alpha, accc):\n",
    "    print(i, j)\n",
    "print(\"alpha :\",list_alpha[accc.index(max(accc))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.8986722689967831\n",
      "0.11 0.9071715311030186\n",
      "0.21000000000000002 0.9094383513648381\n",
      "0.31000000000000005 0.9103658148152081\n",
      "0.41000000000000003 0.9110867741832738\n",
      "0.51 0.9114988798878827\n",
      "0.6100000000000001 0.9111897607950142\n",
      "0.7100000000000001 0.9114989860596474\n",
      "0.81 0.9119629566713028\n",
      "0.91 0.9124265025958996\n",
      "1.01 0.9126325819911452\n",
      "1.11 0.9120141845477615\n",
      "1.2100000000000002 0.9116536783207874\n",
      "1.31 0.9116538375784344\n",
      "1.4100000000000001 0.9125809825135104\n",
      "1.51 0.9123747969465\n",
      "1.61 0.9117565056748809\n",
      "1.7100000000000002 0.9116019195855056\n",
      "1.81 0.9113958401902599\n",
      "1.9100000000000001 0.9108808009597927\n",
      "2.01 0.9109324004374277\n",
      "2.11 0.9104689606845957\n",
      "2.21 0.9104173081210784\n",
      "2.31 0.910726321042182\n",
      "2.41 0.9102109632964211\n",
      "2.51 0.9100050962447048\n",
      "2.61 0.9097990168494592\n",
      "2.71 0.9095414972342255\n",
      "2.81 0.909180884835487\n",
      "2.91 0.909078004395511\n",
      "3.01 0.9079965388004714\n",
      "3.11 0.9074816588276514\n",
      "3.21 0.9066060071984456\n",
      "3.31 0.9062449701126483\n",
      "3.41 0.9060903309373904\n",
      "3.51 0.9055751855351589\n",
      "3.61 0.9049056133011988\n",
      "3.71 0.9042874282013441\n",
      "3.81 0.9041842292460742\n",
      "3.91 0.9035660972321022\n",
      "4.01 0.9028447131769777\n",
      "4.11 0.9020205548536422\n",
      "4.21 0.9007845562551093\n",
      "4.31 0.9007331691210039\n",
      "4.41 0.9004238907704887\n",
      "4.51 0.9000115727223502\n",
      "4.61 0.8995993077600943\n",
      "4.71 0.898723549959124\n",
      "4.8100000000000005 0.8978994447216708\n",
      "4.91 0.897538832322932\n",
      "5.01 0.8971781668383111\n",
      "\n",
      "0.01 0.8986722689967831\n",
      "0.11 0.9071715311030186\n",
      "0.21000000000000002 0.9094383513648381\n",
      "0.31000000000000005 0.9103658148152081\n",
      "0.41000000000000003 0.9110867741832738\n",
      "0.51 0.9114988798878827\n",
      "0.6100000000000001 0.9111897607950142\n",
      "0.7100000000000001 0.9114989860596474\n",
      "0.81 0.9119629566713028\n",
      "0.91 0.9124265025958996\n",
      "1.01 0.9126325819911452\n",
      "1.11 0.9120141845477615\n",
      "1.2100000000000002 0.9116536783207874\n",
      "1.31 0.9116538375784344\n",
      "1.4100000000000001 0.9125809825135104\n",
      "1.51 0.9123747969465\n",
      "1.61 0.9117565056748809\n",
      "1.7100000000000002 0.9116019195855056\n",
      "1.81 0.9113958401902599\n",
      "1.9100000000000001 0.9108808009597927\n",
      "2.01 0.9109324004374277\n",
      "2.11 0.9104689606845957\n",
      "2.21 0.9104173081210784\n",
      "2.31 0.910726321042182\n",
      "2.41 0.9102109632964211\n",
      "2.51 0.9100050962447048\n",
      "2.61 0.9097990168494592\n",
      "2.71 0.9095414972342255\n",
      "2.81 0.909180884835487\n",
      "2.91 0.909078004395511\n",
      "3.01 0.9079965388004714\n",
      "3.11 0.9074816588276514\n",
      "3.21 0.9066060071984456\n",
      "3.31 0.9062449701126483\n",
      "3.41 0.9060903309373904\n",
      "3.51 0.9055751855351589\n",
      "3.61 0.9049056133011988\n",
      "3.71 0.9042874282013441\n",
      "3.81 0.9041842292460742\n",
      "3.91 0.9035660972321022\n",
      "4.01 0.9028447131769777\n",
      "4.11 0.9020205548536422\n",
      "4.21 0.9007845562551093\n",
      "4.31 0.9007331691210039\n",
      "4.41 0.9004238907704887\n",
      "4.51 0.9000115727223502\n",
      "4.61 0.8995993077600943\n",
      "4.71 0.898723549959124\n",
      "4.8100000000000005 0.8978994447216708\n",
      "4.91 0.897538832322932\n",
      "5.01 0.8971781668383111\n",
      "alpha : 1.01\n"
     ]
    }
   ],
   "source": [
    "accc = list()\n",
    "list_alpha = np.arange(0.01, 5+0.1, 0.1)\n",
    "for alp in list_alpha:\n",
    "    lis_sc = list()\n",
    "    for i in range(10):\n",
    "        X = md[\"model_tf\"][i][\"train\"]#.toarray()\n",
    "        Y = np.array(md[\"model_tf\"][i][\"y_train\"])\n",
    "        clf_pf = MultinomialNB(alpha = alp)\n",
    "        for batch in batches(np.arange(X.shape[0]), 1000):\n",
    "            clf_pf.partial_fit(X[batch].A, Y[batch], np.unique(Y))\n",
    "#             clf_pf.fit(X, Y)\n",
    "        sc = clf_pf.score(md[\"model_tf\"][i][\"test\"].A, np.array(md[\"model_tf\"][i][\"y_test\"]))\n",
    "        lis_sc.append(sc)\n",
    "    accc.append(sum(lis_sc)/len(lis_sc))\n",
    "    print(alp, sum(lis_sc)/len(lis_sc))\n",
    "print(\"\")\n",
    "for i, j in zip(list_alpha, accc):\n",
    "    print(i, j)\n",
    "print(\"alpha :\",list_alpha[accc.index(max(accc))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.8979510972851881\n",
      "0.11 0.9063473727796831\n",
      "0.21000000000000002 0.9086654740038436\n",
      "0.31000000000000005 0.9093865926295562\n",
      "0.41000000000000003 0.909850457069447\n",
      "0.51 0.909953390595305\n",
      "0.6100000000000001 0.9102626158599383\n",
      "0.7100000000000001 0.9102107509528915\n",
      "0.81 0.9105197638739954\n",
      "0.91 0.9110351216197564\n",
      "1.01 0.9106746153927825\n",
      "1.11 0.9106231220869121\n",
      "1.2100000000000002 0.9104170426916667\n",
      "1.31 0.9100050431588225\n",
      "1.4100000000000001 0.9097472581141771\n",
      "1.51 0.9094896323271788\n",
      "1.61 0.9095924596812723\n",
      "1.7100000000000002 0.9093865395436739\n",
      "1.81 0.9091801947190165\n",
      "1.9100000000000001 0.9088196884920425\n",
      "2.01 0.9091289137566756\n",
      "2.11 0.9083046492615754\n",
      "2.21 0.9080986760380945\n",
      "2.31 0.9076867295911326\n",
      "2.41 0.9074294754053108\n",
      "2.51 0.9069658763948316\n",
      "2.61 0.9066569165596101\n",
      "2.71 0.9060386783738734\n",
      "2.81 0.9055750262775119\n",
      "2.91 0.9054719865798889\n",
      "3.01 0.9052144138787732\n",
      "3.11 0.9051113741811504\n",
      "3.21 0.9043385499060381\n",
      "3.31 0.9036689245861955\n",
      "3.41 0.9028446600910952\n",
      "3.51 0.9025869812182148\n",
      "3.61 0.901968902290125\n",
      "3.71 0.901350823362035\n",
      "3.81 0.9011446908809072\n",
      "3.91 0.9005780521728053\n",
      "4.01 0.8999602386741271\n",
      "4.11 0.8991876798284265\n",
      "4.21 0.8988785076496757\n",
      "4.31 0.8980025375051758\n",
      "4.41 0.8974360049688388\n",
      "4.51 0.8972298194018282\n",
      "4.61 0.8967147270854788\n",
      "4.71 0.8962508626455878\n",
      "4.8100000000000005 0.895581131153981\n",
      "4.91 0.894808519222398\n",
      "5.01 0.894602492913035\n",
      "\n",
      "0.01 0.8979510972851881\n",
      "0.11 0.9063473727796831\n",
      "0.21000000000000002 0.9086654740038436\n",
      "0.31000000000000005 0.9093865926295562\n",
      "0.41000000000000003 0.909850457069447\n",
      "0.51 0.909953390595305\n",
      "0.6100000000000001 0.9102626158599383\n",
      "0.7100000000000001 0.9102107509528915\n",
      "0.81 0.9105197638739954\n",
      "0.91 0.9110351216197564\n",
      "1.01 0.9106746153927825\n",
      "1.11 0.9106231220869121\n",
      "1.2100000000000002 0.9104170426916667\n",
      "1.31 0.9100050431588225\n",
      "1.4100000000000001 0.9097472581141771\n",
      "1.51 0.9094896323271788\n",
      "1.61 0.9095924596812723\n",
      "1.7100000000000002 0.9093865395436739\n",
      "1.81 0.9091801947190165\n",
      "1.9100000000000001 0.9088196884920425\n",
      "2.01 0.9091289137566756\n",
      "2.11 0.9083046492615754\n",
      "2.21 0.9080986760380945\n",
      "2.31 0.9076867295911326\n",
      "2.41 0.9074294754053108\n",
      "2.51 0.9069658763948316\n",
      "2.61 0.9066569165596101\n",
      "2.71 0.9060386783738734\n",
      "2.81 0.9055750262775119\n",
      "2.91 0.9054719865798889\n",
      "3.01 0.9052144138787732\n",
      "3.11 0.9051113741811504\n",
      "3.21 0.9043385499060381\n",
      "3.31 0.9036689245861955\n",
      "3.41 0.9028446600910952\n",
      "3.51 0.9025869812182148\n",
      "3.61 0.901968902290125\n",
      "3.71 0.901350823362035\n",
      "3.81 0.9011446908809072\n",
      "3.91 0.9005780521728053\n",
      "4.01 0.8999602386741271\n",
      "4.11 0.8991876798284265\n",
      "4.21 0.8988785076496757\n",
      "4.31 0.8980025375051758\n",
      "4.41 0.8974360049688388\n",
      "4.51 0.8972298194018282\n",
      "4.61 0.8967147270854788\n",
      "4.71 0.8962508626455878\n",
      "4.8100000000000005 0.895581131153981\n",
      "4.91 0.894808519222398\n",
      "5.01 0.894602492913035\n",
      "alpha : 0.91\n"
     ]
    }
   ],
   "source": [
    "accc = list()\n",
    "list_alpha = np.arange(0.01, 5+0.1, 0.1)\n",
    "for alp in list_alpha:\n",
    "    lis_sc = list()\n",
    "    for i in range(10):\n",
    "        X = md[\"model_bin\"][i][\"train\"]#.toarray()\n",
    "        Y = np.array(md[\"model_bin\"][i][\"y_train\"])\n",
    "        clf_pf = MultinomialNB(alpha = alp)\n",
    "        for batch in batches(np.arange(X.shape[0]), 1000):\n",
    "            clf_pf.partial_fit(X[batch].A, Y[batch], np.unique(Y))\n",
    "#             clf_pf.fit(X, Y)\n",
    "        sc = clf_pf.score(md[\"model_bin\"][i][\"test\"].A, np.array(md[\"model_bin\"][i][\"y_test\"]))\n",
    "        lis_sc.append(sc)\n",
    "    accc.append(sum(lis_sc)/len(lis_sc))\n",
    "    print(alp, sum(lis_sc)/len(lis_sc))\n",
    "print(\"\")\n",
    "for i, j in zip(list_alpha, accc):\n",
    "    print(i, j)\n",
    "print(\"alpha :\",list_alpha[accc.index(max(accc))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
