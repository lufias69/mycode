{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.naive_bayes import ComplementNB\n",
    "import random\n",
    "from Naive_Bayes import naive_bayes as nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(my_list, n):\n",
    "    final = [my_list[i * n:(i + 1) * n] for i in range((len(my_list) + n - 1) // n )]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(my_list, n):\n",
    "    final = [my_list[i * n:(i + 1) * n] for i in range((len(my_list) + n - 1) // n )]\n",
    "    return final\n",
    "\n",
    "aa = [5,4,3,4,5,6,7,5,6,5,6,7,6,5,4,3,4,5,6,7,8,6,5,4,5,6,7,8,6,6,4]\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "sA = sparse.csr_matrix(aa)   # Here's the initialization of the sparse matrix.\n",
    "# sB = sparse.csr_matrix(B)\n",
    "# for i in batches(sA.A[0], 10):\n",
    "#     print(sparse.csr_matrix(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>komentar</th>\n",
       "      <th>komentar_kotor</th>\n",
       "      <th>kode salah</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66264</th>\n",
       "      <td>66264</td>\n",
       "      <td>non spam</td>\n",
       "      <td>cantik banget pakai gaun kuning viavallen me v...</td>\n",
       "      <td>Cantik banget pakai gaun kuning @viavallen ..m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66265</th>\n",
       "      <td>66265</td>\n",
       "      <td>non spam</td>\n",
       "      <td>gua posesif sama kucing gua gua sering bilang ...</td>\n",
       "      <td>Gua juga posesif sama kucing gua, gua sering b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66266</th>\n",
       "      <td>66266</td>\n",
       "      <td>non spam</td>\n",
       "      <td>kintaro fans ayu ting junjuna nan tuu manusia ...</td>\n",
       "      <td>@kintaro_fans_ayutingting junjuna loo tuu manu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66267</th>\n",
       "      <td>66267</td>\n",
       "      <td>non spam</td>\n",
       "      <td>apa belakang bang dika</td>\n",
       "      <td>Itu apaan ya di belakangnya bang @raditya_dika ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66268</th>\n",
       "      <td>66268</td>\n",
       "      <td>non spam</td>\n",
       "      <td>tahan napas bawang</td>\n",
       "      <td>Nahan napas amat bwangðŸ˜­</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     label  \\\n",
       "66264       66264  non spam   \n",
       "66265       66265  non spam   \n",
       "66266       66266  non spam   \n",
       "66267       66267  non spam   \n",
       "66268       66268  non spam   \n",
       "\n",
       "                                                komentar  \\\n",
       "66264  cantik banget pakai gaun kuning viavallen me v...   \n",
       "66265  gua posesif sama kucing gua gua sering bilang ...   \n",
       "66266  kintaro fans ayu ting junjuna nan tuu manusia ...   \n",
       "66267                             apa belakang bang dika   \n",
       "66268                                 tahan napas bawang   \n",
       "\n",
       "                                          komentar_kotor  kode salah  \n",
       "66264  Cantik banget pakai gaun kuning @viavallen ..m...           0  \n",
       "66265  Gua juga posesif sama kucing gua, gua sering b...           0  \n",
       "66266  @kintaro_fans_ayutingting junjuna loo tuu manu...           0  \n",
       "66267   Itu apaan ya di belakangnya bang @raditya_dika ?           0  \n",
       "66268                            Nahan napas amat bwangðŸ˜­           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# md = joblib.load(\"data.dt\")\n",
    "data_ = pd.read_excel(\"../../data_latih/hasil_seleksi_New3.xlsx\", sheet_name = \"Sheet1\")\n",
    "komentar = data_['komentar'].tolist()\n",
    "label = data_['label'].tolist()\n",
    "data_.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = komentar\n",
    "Y = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";-.;-.;-.;-.;-.;-.;-.;-.;-.;-."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = komentar\n",
    "vectorizer = TfidfVectorizer()\n",
    "model_tfidf = vectorizer.fit(corpus)\n",
    "# print(vectorizer.get_feature_names())\n",
    "# print(X.shape)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X = np.array(komentar)\n",
    "y = np.array(label)\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "skf.get_n_splits(X, y)\n",
    "# print(skf)\n",
    "X_test_list = list()\n",
    "y_test_list = list()\n",
    "model_list = list()\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    model_tfidf = vectorizer.fit(X_train)\n",
    "    \n",
    "    X_test_list.append(model_tfidf.transform(X_test))\n",
    "    y_test_list.append(y_test)\n",
    "    \n",
    "    clf = nb.Gaussian()\n",
    "    print(\";\", end=\"-\")\n",
    "    clf.train(model_tfidf.transform(X_train),y_train)\n",
    "    model_list.append(clf)\n",
    "#     del clf\n",
    "    print(\".\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = komentar\n",
    "vectorizer = TfidfVectorizer()\n",
    "model_tfidf = vectorizer.fit(corpus)\n",
    "# print(vectorizer.get_feature_names())\n",
    "# print(X.shape)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X = np.array(komentar)\n",
    "y = np.array(label)\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "skf.get_n_splits(X, y)\n",
    "# print(skf)\n",
    "X_test_list = list()\n",
    "y_test_list = list()\n",
    "model_list = list()\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(binary=True)\n",
    "    model_tfidf = vectorizer.fit(X_train)\n",
    "    \n",
    "    X_test_list.append(model_tfidf.transform(X_test))\n",
    "    y_test_list.append(y_test)\n",
    "    \n",
    "    clf = nb.Gaussian()\n",
    "    print(\";\", end=\"-\")\n",
    "    clf.train(model_tfidf.transform(X_train),y_train)\n",
    "    model_list.append(clf)\n",
    "#     del clf\n",
    "    print(\".\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.02, 0.12, 0.22, 0.32, 0.42, 0.52, 0.62, 0.72, 0.82, 0.92])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_alpha = np.arange(0.02, 1+0.01, 0.1)\n",
    "print(len(list_alpha))\n",
    "list_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "1e-08 ; 0.7979462334238454\n",
      ".."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-944282be8c7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mtemp_lis_sc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mX_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mtemp_lis_sc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\github\\python\\Naive_Bayes\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict_\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[0mkanan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mstdev_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[0mkanan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mkanan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mliklihood\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkanan\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkiri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_posterior\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mliklihood\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_posterior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accc = list()\n",
    "# list_alpha = np.arange(0.00001, 0.00009+0.00001, 0.00001)\n",
    "for alp in list_alpha:\n",
    "    lis_sc = list()\n",
    "    for i in range(10): \n",
    "        clf = model_list[i]\n",
    "        clf.var_smoothing = alp\n",
    "        print(\".\", end=\"\")\n",
    "        temp_lis_sc = list()\n",
    "        for X_, Y_ in zip(batches(X_test_list[i].A, 100),batches(y_test_list[i], 100)) :\n",
    "            y_pred = clf.predict_(sparse.csr_matrix(X_))\n",
    "            y_true = Y_\n",
    "            temp_lis_sc.append(accuracy_score(y_true, y_pred))\n",
    "            \n",
    "        lis_sc.append(sum(temp_lis_sc)/len(temp_lis_sc))\n",
    "    print(\"\")\n",
    "    accc.append(sum(lis_sc)/len(lis_sc))\n",
    "    print(alp,\";\", sum(lis_sc)/len(lis_sc))\n",
    "for i, j in zip(list_alpha, accc):\n",
    "    print(i,\";\", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..........\n",
    "# 0.001 <=> 0.8752549037474411\n",
    "# ..........\n",
    "# 0.011 <=> 0.9151181333867899\n",
    "# ..........\n",
    "# 0.020999999999999998 <=> 0.9053559795649345\n",
    "# ..........\n",
    "# 0.030999999999999996 <=> 0.9104862014712758\n",
    "# ..........\n",
    "# 0.040999999999999995 <=> 0.915345470449948\n",
    "# ..........\n",
    "# 0.05099999999999999 <=> 0.9206780930512274\n",
    "# ..........\n",
    "# 0.06099999999999999 <=> 0.9243547950115115\n",
    "# ..........\n",
    "# 0.071 <=> 0.925287360511241\n",
    "# ..........\n",
    "# 0.08099999999999999 <=> 0.9204756073114281\n",
    "# ..........\n",
    "# 0.09099999999999998 <=> 0.9057602342378462\n",
    "# ..........\n",
    "# 0.10099999999999998 <=> 0.8857192972864614\n",
    "# ..........\n",
    "# 0.11099999999999999 <=> 0.8683662456946039\n",
    "# ..........\n",
    "# 0.12099999999999998 <=> 0.8596988075495539\n",
    "# ..........\n",
    "# 0.13099999999999998 <=> 0.852506363178005\n",
    "# ..........\n",
    "# 0.141 <=> 0.8493810435004466\n",
    "# ..........\n",
    "# 0.15099999999999997 <=> 0.8481018837436748"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";-.;-.;-.;-.;-.;-.;-.;-.;-.;-...........\n",
      "0.02 ; 0.7776112295664533\n",
      "..........\n",
      "0.12000000000000001 ; 0.7787555203226846\n",
      "..........\n",
      "0.22 ; 0.8361052430156908\n",
      "..........\n",
      "0.32000000000000006 ; 0.9063909451521391\n",
      "..........\n",
      "0.42000000000000004 ; 0.9238888524410912\n",
      "..........\n",
      "0.52 ; 0.8954531433188148\n",
      "..........\n",
      "0.6200000000000001 ; 0.8923395841306287\n",
      "..........\n",
      "0.7200000000000001 ; 0.8816847872967275\n",
      "..........\n",
      "0.8200000000000001 ; 0.8703888372545089\n",
      "..........\n",
      "0.92 ; 0.8638306939053209\n",
      "0.02 ; 0.7776112295664533\n",
      "0.12000000000000001 ; 0.7787555203226846\n",
      "0.22 ; 0.8361052430156908\n",
      "0.32000000000000006 ; 0.9063909451521391\n",
      "0.42000000000000004 ; 0.9238888524410912\n",
      "0.52 ; 0.8954531433188148\n",
      "0.6200000000000001 ; 0.8923395841306287\n",
      "0.7200000000000001 ; 0.8816847872967275\n",
      "0.8200000000000001 ; 0.8703888372545089\n",
      "0.92 ; 0.8638306939053209\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X = np.array(komentar)\n",
    "y = np.array(label)\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "skf.get_n_splits(X, y)\n",
    "# print(skf)\n",
    "X_test_list = list()\n",
    "y_test_list = list()\n",
    "model_list = list()\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    model = vectorizer.fit(X_train)\n",
    "    \n",
    "    X_test_list.append(model.transform(X_test))\n",
    "    y_test_list.append(y_test)\n",
    "    \n",
    "    clf = nb.Gaussian()\n",
    "    print(\";\", end=\"-\")\n",
    "    clf.train(model.transform(X_train),y_train)\n",
    "    model_list.append(clf)\n",
    "#     del clf\n",
    "    print(\".\", end=\"\")\n",
    "    \n",
    "from sklearn.metrics import accuracy_score\n",
    "accc = list()\n",
    "# list_alpha = np.arange(0.00001, 0.00009+0.00001, 0.00001)\n",
    "for alp in list_alpha:\n",
    "    lis_sc = list()\n",
    "    for i in range(10): \n",
    "        clf = model_list[i]\n",
    "        clf.var_smoothing = alp\n",
    "        print(\".\", end=\"\")\n",
    "        temp_lis_sc = list()\n",
    "        for X_, Y_ in zip(batches(X_test_list[i].A, 100),batches(y_test_list[i], 100)) :\n",
    "            y_pred = clf.predict_(sparse.csr_matrix(X_))\n",
    "            y_true = Y_\n",
    "            temp_lis_sc.append(accuracy_score(y_true, y_pred))\n",
    "            \n",
    "        lis_sc.append(sum(temp_lis_sc)/len(temp_lis_sc))\n",
    "    print(\"\")\n",
    "    accc.append(sum(lis_sc)/len(lis_sc))\n",
    "    print(alp,\";\", sum(lis_sc)/len(lis_sc))\n",
    "for i, j in zip(list_alpha, accc):\n",
    "    print(i,\";\", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ;-.;-.;-.;-.;-.;-.;-.;-.;-.;-...........\n",
    "# 1e-09 ; 0.7979462334238454\n",
    "# 0.0001 ; 0.7979163826775766\n",
    "# ..........\n",
    "# 0.0011 ; 0.7971850393939947\n",
    "# ..........\n",
    "# 0.0021 ; 0.7963726726562548\n",
    "# ..........\n",
    "# 0.0031 ; 0.7950782716454359\n",
    "# ..........\n",
    "# 0.0041 ; 0.7946603611976746\n",
    "# ..........\n",
    "# 0.0051 ; 0.7933872821484763\n",
    "# ..........\n",
    "# 0.0061 ; 0.7923359575747636\n",
    "# ..........\n",
    "# 0.0071 ; 0.7918434202613309\n",
    "# ..........\n",
    "# 0.0081 ; 0.7907922475534417\n",
    "# ..........\n",
    "# 0.0091 ; 0.7903295609862775\n",
    "# ..........\n",
    "# 0.0101 ; 0.7897322301799915\n",
    "\n",
    "# 0.92 ; 0.8638306939053209\n",
    "# 0.02 ; 0.7776112295664533\n",
    "# 0.12000000000000001 ; 0.7787555203226846\n",
    "# 0.22 ; 0.8361052430156908\n",
    "# 0.32000000000000006 ; 0.9063909451521391\n",
    "# 0.42000000000000004 ; 0.9238888524410912\n",
    "# 0.52 ; 0.8954531433188148\n",
    "# 0.6200000000000001 ; 0.8923395841306287\n",
    "# 0.7200000000000001 ; 0.8816847872967275\n",
    "# 0.8200000000000001 ; 0.8703888372545089\n",
    "# 0.92 ; 0.8638306939053209\n",
    "# 0.100000001 ; 0.7744646911960344\n",
    "# .........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";-.;-.;-.;-.;-.;-.;-.;-.;-.;-...........\n",
      "0.02 ; 0.7896282810611168\n",
      "........"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# X = np.array(komentar)\n",
    "y = np.array(label)\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "skf.get_n_splits(X, y)\n",
    "# print(skf)\n",
    "X_test_list = list()\n",
    "y_test_list = list()\n",
    "model_list = list()\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    vectorizer = CountVectorizer(binary=True)\n",
    "    model = vectorizer.fit(X_train)\n",
    "    \n",
    "    X_test_list.append(model.transform(X_test))\n",
    "    y_test_list.append(y_test)\n",
    "    \n",
    "    clf = nb.Gaussian()\n",
    "    print(\";\", end=\"-\")\n",
    "    clf.train(model.transform(X_train),y_train)\n",
    "    model_list.append(clf)\n",
    "#     del clf\n",
    "    print(\".\", end=\"\")\n",
    "    \n",
    "from sklearn.metrics import accuracy_score\n",
    "accc = list()\n",
    "# list_alpha = np.arange(0.00001, 0.00009+0.00001, 0.00001)\n",
    "for alp in list_alpha:\n",
    "    lis_sc = list()\n",
    "    for i in range(10): \n",
    "        clf = model_list[i]\n",
    "        clf.var_smoothing = alp\n",
    "        print(\".\", end=\"\")\n",
    "        temp_lis_sc = list()\n",
    "        for X_, Y_ in zip(batches(X_test_list[i].A, 100),batches(y_test_list[i], 100)) :\n",
    "            y_pred = clf.predict_(sparse.csr_matrix(X_))\n",
    "            y_true = Y_\n",
    "            temp_lis_sc.append(accuracy_score(y_true, y_pred))\n",
    "            \n",
    "        lis_sc.append(sum(temp_lis_sc)/len(temp_lis_sc))\n",
    "    print(\"\")\n",
    "    accc.append(sum(lis_sc)/len(lis_sc))\n",
    "    print(alp,\";\", sum(lis_sc)/len(lis_sc))\n",
    "for i, j in zip(list_alpha, accc):\n",
    "    print(i,\";\", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.03900001 ; 0.7927029140014215\n",
    "1e-08 ; 0.8076407705064422\n",
    "0.00100001 ; 0.8073734562839039\n",
    "0.00200001 ; 0.8064497415243684\n",
    "0.00300001 ; 0.8058228758527267\n",
    "0.00400001 ; 0.8047695770233085\n",
    "0.00500001 ; 0.8040124894453253\n",
    "0.00600001 ; 0.803129766308871\n",
    "0.00700001 ; 0.8029180471270024\n",
    "0.00800001 ; 0.8019815331158615\n",
    "0.009000010000000001 ; 0.8011519447937359\n",
    "0.01000001 ; 0.8003650064694842\n",
    "0.01100001 ; 0.7995949677740724\n",
    "0.01200001 ; 0.7982367588188485\n",
    "0.013000010000000001 ; 0.7975457693218889\n",
    "0.01400001 ; 0.7970294619697605\n",
    "0.01500001 ; 0.7964708265753042\n",
    "0.016000010000000002 ; 0.7942425236455087\n",
    "0.017000010000000003 ; 0.7924557371870807\n",
    "0.018000010000000004 ; 0.7910015794045646\n",
    "0.01900001 ; 0.7902041380399589\n",
    "0.020000010000000002 ; 0.7896282810611168\n",
    "0.021000010000000003 ; 0.7890544044126134\n",
    "0.02200001 ; 0.7886278011651146\n",
    "0.02300001 ; 0.7887898541480631\n",
    "0.024000010000000002 ; 0.7881349479707689\n",
    "0.025000010000000003 ; 0.7880813271858049\n",
    "0.026000010000000004 ; 0.7875077664182143\n",
    "0.02700001 ; 0.7879465128569606\n",
    "0.028000010000000002 ; 0.7881976321080798\n",
    "0.029000010000000003 ; 0.788653606205845\n",
    "0.03000001 ; 0.7889577084054696\n",
    "0.03100001 ; 0.7900767955096315\n",
    "0.03200001 ; 0.7905045711612876\n",
    "0.03300001 ; 0.7906899082122963\n",
    "0.034000010000000004 ; 0.7909433236746668\n",
    "0.035000010000000005 ; 0.7915464193076134\n",
    "0.036000010000000006 ; 0.7918191824758989\n",
    "0.03700001 ; 0.792068491486402\n",
    "0.03800001 ; 0.7921341096714232\n",
    "0.03900001 ; 0.7927029140014215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['non spam', 'non spam', 'non spam', ..., 'spam', 'spam', 'spam'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accc = list()\n",
    "# list_alpha = np.arange(0.00001, 0.00009+0.00001, 0.00001)\n",
    "for alp in list_alpha:\n",
    "    \n",
    "    lis_sc = list()\n",
    "    for i in range(10): \n",
    "        X = md[\"model_tf\"][i][\"train\"]#.toarray()\n",
    "        Y = np.array(md[\"model_tf\"][i][\"y_train\"])\n",
    "        clf = nb.Gaussian(var_smoothing = alp)\n",
    "        clf.train(X,Y)\n",
    "        print(\".\", end=\"\")\n",
    "        y_pred = clf.predict_(md[\"model_tf_idf\"][i][\"test\"])\n",
    "        y_true = md[\"model_tf_idf\"][i][\"y_test\"]\n",
    "        lis_sc.append(accuracy_score(y_true, y_pred))\n",
    "    print(\"\")\n",
    "    accc.append(sum(lis_sc)/len(lis_sc))\n",
    "    print(alp,\"<=>\", sum(lis_sc)/len(lis_sc))\n",
    "for i, j in zip(alp, accc):\n",
    "    print(i,\";\", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'md' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-fdeaf9ab4b18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mlis_sc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model_bin\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;31m#.toarray()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model_bin\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"y_train\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGaussian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_smoothing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'md' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accc = list()\n",
    "# list_alpha = np.arange(0.00001, 0.00009+0.00001, 0.00001)\n",
    "for alp in list_alpha:\n",
    "    \n",
    "    lis_sc = list()\n",
    "    for i in range(10): \n",
    "        X = md[\"model_bin\"][i][\"train\"]#.toarray()\n",
    "        Y = np.array(md[\"model_bin\"][i][\"y_train\"])\n",
    "        clf = nb.Gaussian(var_smoothing = alp)\n",
    "        clf.train(X,Y)\n",
    "        print(\".\", end=\"\")\n",
    "        y_pred = clf.predict_(md[\"model_tf_idf\"][i][\"test\"])\n",
    "        y_true = md[\"model_tf_idf\"][i][\"y_test\"]\n",
    "        lis_sc.append(accuracy_score(y_true, y_pred))\n",
    "    print(\"\")\n",
    "    accc.append(sum(lis_sc)/len(lis_sc))\n",
    "    print(alp,\"<=>\", sum(lis_sc)/len(lis_sc))\n",
    "for i, j in zip(alp, accc):\n",
    "    print(i,\";\", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003 0.6429366874955111\n",
      "0.013000000000000001 0.6459209581268408\n"
     ]
    }
   ],
   "source": [
    "accc = list()\n",
    "\n",
    "for alp in list_alpha:\n",
    "    lis_sc = list()\n",
    "    for i in range(10):\n",
    "        X = md[\"model_tf_idf\"][i][\"train\"]#.toarray()\n",
    "        Y = np.array(md[\"model_tf_idf\"][i][\"y_train\"])\n",
    "        clf_pf = GaussianNB(var_smoothing = alp)\n",
    "        for batch in batches(np.arange(X.shape[0]), 1000):\n",
    "            clf_pf.partial_fit(X[batch].A, Y[batch], np.unique(Y))\n",
    "#             clf_pf.fit(X, Y)\n",
    "        lisskor_batch = list()\n",
    "        for batch in batches(np.arange(md[\"model_tf_idf\"][i][\"test\"].shape[0]), 10):\n",
    "            sc = clf_pf.score(md[\"model_tf_idf\"][i][\"test\"][batch].A, np.array(md[\"model_tf_idf\"][i][\"y_test\"])[batch])\n",
    "            lisskor_batch.append(sc)\n",
    "        lis_sc.append(sum(lisskor_batch)/len(lisskor_batch))\n",
    "        \n",
    "    accc.append(sum(lis_sc)/len(lis_sc))\n",
    "    print(alp, sum(lis_sc)/len(lis_sc))\n",
    "print(\"\")\n",
    "for i, j in zip(list_alpha, accc):\n",
    "    print(i, j)\n",
    "print(\"alpha :\",list_alpha[accc.index(max(accc))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.9196089204912692\n",
      "0.00030000000000000003 0.9454083171730188\n",
      "0.0005000000000000001 0.9436184730302337\n",
      "0.0007000000000000001 0.9400438123967497\n",
      "0.0009000000000000002 0.9362881562881522\n",
      "0.0011000000000000003 0.9325174172232955\n",
      "0.0013000000000000002 0.928867341808514\n",
      "0.0015000000000000002 0.9253680959563271\n",
      "0.0017000000000000003 0.922291172879404\n",
      "0.0019000000000000004 0.9197421532715611\n",
      "0.0021000000000000003 0.9167406449759351\n",
      "\n",
      "0.0001 0.9196089204912692\n",
      "0.00030000000000000003 0.9454083171730188\n",
      "0.0005000000000000001 0.9436184730302337\n",
      "0.0007000000000000001 0.9400438123967497\n",
      "0.0009000000000000002 0.9362881562881522\n",
      "0.0011000000000000003 0.9325174172232955\n",
      "0.0013000000000000002 0.928867341808514\n",
      "0.0015000000000000002 0.9253680959563271\n",
      "0.0017000000000000003 0.922291172879404\n",
      "0.0019000000000000004 0.9197421532715611\n",
      "0.0021000000000000003 0.9167406449759351\n",
      "alpha : 0.00030000000000000003\n"
     ]
    }
   ],
   "source": [
    "accc = list()\n",
    "\n",
    "for alp in list_alpha:\n",
    "    lis_sc = list()\n",
    "    for i in range(10):\n",
    "        X = md[\"model_tf\"][i][\"train\"]#.toarray()\n",
    "        Y = np.array(md[\"model_tf\"][i][\"y_train\"])\n",
    "        clf_pf = GaussianNB(var_smoothing = alp)\n",
    "        for batch in batches(np.arange(X.shape[0]), 1000):\n",
    "            clf_pf.partial_fit(X[batch].A, Y[batch], np.unique(Y))\n",
    "#             clf_pf.fit(X, Y)\n",
    "        lisskor_batch = list()\n",
    "        for batch in batches(np.arange(md[\"model_tf\"][i][\"test\"].shape[0]), 10):\n",
    "            sc = clf_pf.score(md[\"model_tf\"][i][\"test\"][batch].A, np.array(md[\"model_tf\"][i][\"y_test\"])[batch])\n",
    "            lisskor_batch.append(sc)\n",
    "        lis_sc.append(sum(lisskor_batch)/len(lisskor_batch))\n",
    "        \n",
    "    accc.append(sum(lis_sc)/len(lis_sc))\n",
    "    print(alp, sum(lis_sc)/len(lis_sc))\n",
    "print(\"\")\n",
    "for i, j in zip(list_alpha, accc):\n",
    "    print(i, j)\n",
    "print(\"alpha :\",list_alpha[accc.index(max(accc))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accc = list()\n",
    "\n",
    "for alp in list_alpha:\n",
    "    lis_sc = list()\n",
    "    for i in range(10):\n",
    "        X = md[\"model_bin\"][i][\"train\"]#.toarray()\n",
    "        Y = np.array(md[\"model_bin\"][i][\"y_train\"])\n",
    "        clf_pf = GaussianNB(var_smoothing = alp)\n",
    "        for batch in batches(np.arange(X.shape[0]), 1000):\n",
    "            clf_pf.partial_fit(X[batch].A, Y[batch], np.unique(Y))\n",
    "#             clf_pf.fit(X, Y)\n",
    "        lisskor_batch = list()\n",
    "        for batch in batches(np.arange(md[\"model_bin\"][i][\"test\"].shape[0]), 10):\n",
    "            sc = clf_pf.score(md[\"model_tf\"][i][\"test\"][batch].A, np.array(md[\"model_bin\"][i][\"y_test\"])[batch])\n",
    "            lisskor_batch.append(sc)\n",
    "        lis_sc.append(sum(lisskor_batch)/len(lisskor_batch))\n",
    "        \n",
    "    accc.append(sum(lis_sc)/len(lis_sc))\n",
    "    print(alp, sum(lis_sc)/len(lis_sc))\n",
    "print(\"\")\n",
    "for i, j in zip(list_alpha, accc):\n",
    "    print(i, j)\n",
    "print(\"alpha :\",list_alpha[accc.index(max(accc))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
