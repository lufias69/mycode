{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from Naive_Bayes import naive_bayes as nb\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(my_list, n):\n",
    "    final = [my_list[i * n:(i + 1) * n] for i in range((len(my_list) + n - 1) // n )]\n",
    "    return np.array(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>komentar</th>\n",
       "      <th>komentar_kotor</th>\n",
       "      <th>kode salah</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66264</th>\n",
       "      <td>66264</td>\n",
       "      <td>non spam</td>\n",
       "      <td>cantik banget pakai gaun kuning viavallen me v...</td>\n",
       "      <td>Cantik banget pakai gaun kuning @viavallen ..m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66265</th>\n",
       "      <td>66265</td>\n",
       "      <td>non spam</td>\n",
       "      <td>gua posesif sama kucing gua gua sering bilang ...</td>\n",
       "      <td>Gua juga posesif sama kucing gua, gua sering b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66266</th>\n",
       "      <td>66266</td>\n",
       "      <td>non spam</td>\n",
       "      <td>kintaro fans ayu ting junjuna nan tuu manusia ...</td>\n",
       "      <td>@kintaro_fans_ayutingting junjuna loo tuu manu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66267</th>\n",
       "      <td>66267</td>\n",
       "      <td>non spam</td>\n",
       "      <td>apa belakang bang dika</td>\n",
       "      <td>Itu apaan ya di belakangnya bang @raditya_dika ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66268</th>\n",
       "      <td>66268</td>\n",
       "      <td>non spam</td>\n",
       "      <td>tahan napas bawang</td>\n",
       "      <td>Nahan napas amat bwangðŸ˜­</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     label  \\\n",
       "66264       66264  non spam   \n",
       "66265       66265  non spam   \n",
       "66266       66266  non spam   \n",
       "66267       66267  non spam   \n",
       "66268       66268  non spam   \n",
       "\n",
       "                                                komentar  \\\n",
       "66264  cantik banget pakai gaun kuning viavallen me v...   \n",
       "66265  gua posesif sama kucing gua gua sering bilang ...   \n",
       "66266  kintaro fans ayu ting junjuna nan tuu manusia ...   \n",
       "66267                             apa belakang bang dika   \n",
       "66268                                 tahan napas bawang   \n",
       "\n",
       "                                          komentar_kotor  kode salah  \n",
       "66264  Cantik banget pakai gaun kuning @viavallen ..m...           0  \n",
       "66265  Gua juga posesif sama kucing gua, gua sering b...           0  \n",
       "66266  @kintaro_fans_ayutingting junjuna loo tuu manu...           0  \n",
       "66267   Itu apaan ya di belakangnya bang @raditya_dika ?           0  \n",
       "66268                            Nahan napas amat bwangðŸ˜­           0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ = pd.read_excel(\"../../data_latih/hasil_seleksi_New3.xlsx\", sheet_name = \"Sheet1\")\n",
    "komentar = data_['komentar'].tolist()\n",
    "label = data_['label'].tolist()\n",
    "data_.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X = np.array(komentar)\n",
    "y = np.array(label)\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "skf.get_n_splits(X, y)\n",
    "print(skf)\n",
    "\n",
    "X_train_list = list()\n",
    "y_train_list = list()\n",
    "\n",
    "X_test_list = list()\n",
    "y_test_list = list()\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    X_train_list.append(X_train)\n",
    "    y_train_list.append(y_train)\n",
    "    \n",
    "    X_test_list.append(X_test)\n",
    "    y_test_list.append(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del komentar\n",
    "del label\n",
    "del data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list=list()\n",
    "for X_, y_ in zip(X_train_list, y_train_list):\n",
    "    model = nb.NaiveBayesClassifier()\n",
    "    model.train(X_, y_)\n",
    "    model_list.append(model)\n",
    "    \n",
    "del X_train_list\n",
    "del y_train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_list = np.arange(0.1, 2+ 0.1, 0.1)\n",
    "alpha_list = np.arange(1, 2+ 0.1,1)\n",
    "alpha_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-.-.-.-.-.-.-.-.-.-.\n",
      "1.0 0.9624626517273542\n",
      "\n",
      "-.-.-.-.-"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "skor_list = list()\n",
    "for alpha in alpha_list:\n",
    "    skor_list_temp = list()\n",
    "    for i in range(10):\n",
    "        print(\"-\", end=\"\")\n",
    "        model = model_list[i]\n",
    "        model.alpha = alpha\n",
    "        \n",
    "#         y_pred = model.predict_(X_test_list[i])\n",
    "#         y_true = y_test_list[i]\n",
    "        sc_temp = list()\n",
    "        for X, y_true in zip(batches(X_test_list[i], 10), batches(y_test_list[i], 10)):\n",
    "            y_pred = model.predict_(X)\n",
    "#             y_true = y\n",
    "            sc_temp.append(accuracy_score(y_true, y_pred))\n",
    "        skor_list_temp.append(sum(sc_temp)/len(sc_temp)) \n",
    "        print(\".\", end=\"\")\n",
    "        \n",
    "    skor_list.append(sum(skor_list_temp)/len(skor_list_temp))\n",
    "    print(\"\")\n",
    "    print(alpha, sum(skor_list_temp)/len(skor_list_temp))\n",
    "    print(\"\")\n",
    "print(\"\")    \n",
    "for i, j in zip(alpha_list, skor_list):\n",
    "    print(i,\";\",j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-.-.-.-.-.-.-.-.-.-.\n",
    "0.1 0.9606302197152651\n",
    "\n",
    "-.-.-.-.-.-.-.-.-.-.\n",
    "0.2 0.9613696419216335\n",
    "\n",
    "-.-.-.-.-.-.-.-.-.-.\n",
    "0.30000000000000004 0.9617016126237914\n",
    "\n",
    "-.-.-.-.-.-.-.-.-.-.\n",
    "0.4 0.9620788617873484\n",
    "\n",
    "-.-.-.-.-.-.-.-.-.-.\n",
    "0.5 0.9621090368017489"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def batches(my_list, n):\n",
    "#     final = [my_list[i * n:(i + 1) * n] for i in range((len(my_list) + n - 1) // n )]\n",
    "#     return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# md = joblib.load(\"data.dt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_alpha = np.arange(20.5, 25+0.5, 0.5)\n",
    "# list_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accc = list()\n",
    "\n",
    "# for alp in list_alpha:\n",
    "#     lis_sc = list()\n",
    "#     for i in range(10):\n",
    "#         X = md[\"model_tf_idf\"][i][\"train\"]#.toarray()\n",
    "#         Y = np.array(md[\"model_tf_idf\"][i][\"y_train\"])\n",
    "#         clf_pf = ComplementNB(alpha = alp)\n",
    "#         for batch in batches(np.arange(X.shape[0]), 1000):\n",
    "#             clf_pf.partial_fit(X[batch].A, Y[batch], np.unique(Y))\n",
    "# #             clf_pf.fit(X, Y)\n",
    "#         lisskor_batch = list()\n",
    "#         for batch in batches(np.arange(md[\"model_tf_idf\"][i][\"test\"].shape[0]), 10):\n",
    "#             sc = clf_pf.score(md[\"model_tf_idf\"][i][\"test\"][batch].A, np.array(md[\"model_tf_idf\"][i][\"y_test\"])[batch])\n",
    "#             lisskor_batch.append(sc)\n",
    "#         lis_sc.append(sum(lisskor_batch)/len(lisskor_batch))\n",
    "#     accc.append(sum(lis_sc)/len(lis_sc))\n",
    "#     print(alp, sum(lis_sc)/len(lis_sc))\n",
    "# print(\"\")\n",
    "# for i, j in zip(list_alpha, accc):\n",
    "#     print(i, j)\n",
    "# print(\"alpha :\",list_alpha[accc.index(max(accc))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accc = list()\n",
    "# # list_alpha = np.arange(0.01, 5+0.1, 0.1)\n",
    "# for alp in list_alpha:\n",
    "#     lis_sc = list()\n",
    "#     for i in range(10):\n",
    "#         X = md[\"model_tf\"][i][\"train\"]#.toarray()\n",
    "#         Y = np.array(md[\"model_tf\"][i][\"y_train\"])\n",
    "#         clf_pf = ComplementNB(alpha = alp)\n",
    "#         for batch in batches(np.arange(X.shape[0]), 1000):\n",
    "#             clf_pf.partial_fit(X[batch].A, Y[batch], np.unique(Y))\n",
    "# #             clf_pf.fit(X, Y)\n",
    "#         lisskor_batch = list()\n",
    "#         for batch in batches(np.arange(md[\"model_tf_idf\"][i][\"test\"].shape[0]), 10):\n",
    "#             sc = clf_pf.score(md[\"model_tf_idf\"][i][\"test\"][batch].A, np.array(md[\"model_tf_idf\"][i][\"y_test\"])[batch])\n",
    "#             lisskor_batch.append(sc)\n",
    "#         lis_sc.append(sum(lisskor_batch)/len(lisskor_batch))\n",
    "#     accc.append(sum(lis_sc)/len(lis_sc))\n",
    "#     print(alp, sum(lis_sc)/len(lis_sc))\n",
    "# print(\"\")\n",
    "# for i, j in zip(list_alpha, accc):\n",
    "#     print(i, j)\n",
    "# print(\"alpha :\",list_alpha[accc.index(max(accc))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accc = list()\n",
    "# # list_alpha = np.arange(0.01, 5+0.1, 0.1)\n",
    "# for alp in list_alpha:\n",
    "#     lis_sc = list()\n",
    "#     for i in range(10):\n",
    "#         X = md[\"model_bin\"][i][\"train\"]#.toarray()\n",
    "#         Y = np.array(md[\"model_bin\"][i][\"y_train\"])\n",
    "#         clf_pf = ComplementNB(alpha = alp)\n",
    "#         for batch in batches(np.arange(X.shape[0]), 1000):\n",
    "#             clf_pf.partial_fit(X[batch].A, Y[batch], np.unique(Y))\n",
    "# #             clf_pf.fit(X, Y)\n",
    "#         lisskor_batch = list()\n",
    "#         for batch in batches(np.arange(md[\"model_tf_idf\"][i][\"test\"].shape[0]), 10):\n",
    "#             sc = clf_pf.score(md[\"model_tf_idf\"][i][\"test\"][batch].A, np.array(md[\"model_tf_idf\"][i][\"y_test\"])[batch])\n",
    "#             lisskor_batch.append(sc)\n",
    "#         lis_sc.append(sum(lisskor_batch)/len(lisskor_batch))\n",
    "#     accc.append(sum(lis_sc)/len(lis_sc))\n",
    "#     print(alp, sum(lis_sc)/len(lis_sc))\n",
    "# print(\"\")\n",
    "# for i, j in zip(list_alpha, accc):\n",
    "#     print(i, j)\n",
    "# print(\"alpha :\",list_alpha[accc.index(max(accc))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
