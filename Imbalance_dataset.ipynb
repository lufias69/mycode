{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from Naive_Bayes import naive_bayes as nb\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imbang_data_k_fold_10.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = [\n",
    "#     'This is the first document.',\n",
    "#     'This document is the second document.',\n",
    "#     'And this is the third one.',\n",
    "#     'Is this the first document?',\n",
    "# # ]\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(corpus)\n",
    "# print(vectorizer.get_feature_names())\n",
    "\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.2.3.4.5.6.7.8.9."
     ]
    }
   ],
   "source": [
    "model_tf_idf = list()\n",
    "model_tf = list()\n",
    "model_bin = list()\n",
    "# list_model = list()\n",
    "for ix, i in enumerate(data):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit(i['X_train'])\n",
    "    data_latih = X.transform(i['X_train'])\n",
    "    data_uji = X.transform(i['X_test'])\n",
    "    dc={\n",
    "        \"model\":X,\n",
    "        \"train\":data_latih,\n",
    "        \"test\":data_uji,\n",
    "        \"y_train\":i['y_train'],\n",
    "        \"y_test\":i['y_test'],\n",
    "    }\n",
    "    model_tf_idf.append(dc)\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit(i['X_train'])\n",
    "    data_latih = X.transform(i['X_train'])\n",
    "    data_uji = X.transform(i['X_test'])\n",
    "    dc={\n",
    "        \"model\":X,\n",
    "        \"train\":data_latih,\n",
    "        \"test\":data_uji,\n",
    "        \"y_train\":i['y_train'],\n",
    "        \"y_test\":i['y_test'],\n",
    "    }\n",
    "    model_tf.append(dc)\n",
    "    \n",
    "    \n",
    "    vectorizer = CountVectorizer(binary=True)\n",
    "    X = vectorizer.fit(i['X_train'])\n",
    "    data_latih = X.transform(i['X_train'])\n",
    "    data_uji = X.transform(i['X_test'])\n",
    "    dc={\n",
    "        \"model\":X,\n",
    "        \"train\":data_latih,\n",
    "        \"test\":data_uji,\n",
    "        \"y_train\":i['y_train'],\n",
    "        \"y_test\":i['y_test'],\n",
    "    }\n",
    "    model_bin.append(dc)\n",
    "    \n",
    "    \n",
    "    print(ix,end=\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kfolds proses/imbang_data.dt']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "dict_model_ = {\n",
    "    \"model_tf_idf\":model_tf_idf,\n",
    "    \"model_tf\":model_tf,\n",
    "    \"model_bin\":model_bin \n",
    "}\n",
    "joblib.dump(dict_model_,\"kfolds proses/imbang_data.dt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.2.3.4.5.6.7.8.9."
     ]
    }
   ],
   "source": [
    "\n",
    "model_ = dict()\n",
    "list_model = list()\n",
    "for ix, i in enumerate(data):\n",
    "    model = nb.NaiveBayesClassifier()\n",
    "    X = i['X_train']\n",
    "    y = np.array(i['y_train'])\n",
    "    model.train(X,y)\n",
    "#     joblib.dump(m,\"model_naive_bayes_kf/\"+str(ix)+\"_model.nbc\")\n",
    "#     joblib.dump(model,\"model_naive_bayes_kf/\"+str(ix)+\"_model.nbc\")\n",
    "    list_model.append(model)\n",
    "    print(ix,end=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non spam']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_model[1].predict_([\"kak suka langsing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = np.arange(3.5, 7+0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.40.41.42.43.44.45.46.47.48.49.50.51.52.53.54.55.56.57.58.59.60.61.62.63.64.65.66.67.68.69.70.71.72.73.74.75.76.77.78.79.80.81.82.83.84.85.86.87.88.89.90.91.92.93.94.95.96.97.98.99.0.5 | 0.9700840807469996\n"
     ]
    }
   ],
   "source": [
    "akurasi = list()\n",
    "ixx= 0 \n",
    "for alpha in alpha_list:\n",
    "    acc_iterasi = list()\n",
    "    for model in list_model:\n",
    "        model.alpha = alpha\n",
    "        for ix, i in enumerate(data):\n",
    "            print(ixx, end='.')\n",
    "            ixx+=1\n",
    "            X = i['X_test']\n",
    "            y = np.array(i['y_test'])\n",
    "            y_ = model.predict_(X)\n",
    "            y_pred = y_\n",
    "            y_true = y\n",
    "            acc_iterasi.append(accuracy_score(y_true, y_pred))\n",
    "    akurasi.append(sum(acc_iterasi)/len(acc_iterasi))\n",
    "    print(alpha, \"|\", sum(acc_iterasi)/len(acc_iterasi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.40.41.42.43.44.45.46.47.48.49.50.51.52.53.54.55.56.57.58.59.60.61.62.63.64.65.66.67.68.69.70.71.72.73.74.75.76.77.78.79.80.81.82.83.84.85.86.87.88.89.90.91.92.93.94.95.96.97.98.99.0.5 | 0.9700840807469998\n",
      "100.101.102.103.104.105.106.107.108.109.110.111.112.113.114.115.116.117.118.119.120.121.122.123.124.125.126.127.128.129.130.131.132.133.134.135.136.137.138.139.140.141.142.143.144.145.146.147.148.149.150.151.152.153.154.155.156.157.158.159.160.161.162.163.164.165.166.167.168.169.170.171.172.173.174.175.176.177.178.179.180.181.182.183.184.185.186.187.188.189.190.191.192.193.194.195.196.197.198.199.1.0 | 0.9687290008049868\n",
      "200.201.202.203.204.205.206.207.208.209.210.211.212.213."
     ]
    }
   ],
   "source": [
    "akurasi = list()\n",
    "ixx= 0 \n",
    "for alpha in alpha_list:\n",
    "    acc_iterasi = list()\n",
    "    for model in list_model:\n",
    "        model.alpha = alpha\n",
    "        for ix, i in enumerate(data):\n",
    "            print(ixx, end='.')\n",
    "            ixx+=1\n",
    "            X = i['X_test']\n",
    "            y = np.array(i['y_test'])\n",
    "            y_ = model.predict(X)\n",
    "            y_pred = y_\n",
    "            y_true = y\n",
    "            acc_iterasi.append(accuracy_score(y_true, y_pred))\n",
    "    akurasi.append(sum(acc_iterasi)/len(acc_iterasi))\n",
    "    print(alpha, \"|\", sum(acc_iterasi)/len(acc_iterasi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 9],\n",
       "       [2, 2, 2, 2],\n",
       "       [3, 3, 3, 3],\n",
       "       [4, 4, 4, 4],\n",
       "       [5, 5, 5, 5],\n",
       "       [6, 6, 6, 6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "m =[\n",
    "    [1,2,3,4,5,6],\n",
    "    [1,2,3,4,5,6],\n",
    "    [1,2,3,4,5,6],\n",
    "    [9,2,3,4,5,6]\n",
    "]\n",
    "\n",
    "m = np.array(m)\n",
    "m.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x6 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 22 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix, find\n",
    "\n",
    "m =[\n",
    "    [1,2,3,3,1,6],\n",
    "    [2,4,1,2,2,1],\n",
    "    [2,2,1,2,1,0],\n",
    "    [9,1,2,4,0,3]\n",
    "]\n",
    "\n",
    "# m = np.matrix(m)\n",
    "m = sparse.csr_matrix(m)\n",
    "m.max(0).A\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  8,  9, 12,  2, 36],\n",
       "       [18, 16,  3,  8,  4,  6],\n",
       "       [18,  8,  3,  8,  2,  0],\n",
       "       [81,  4,  6, 16,  0, 18]], dtype=int32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.A*m.max(0).A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " array([0, 1, 2, 3, 4, 5], dtype=int32),\n",
       " array([9, 4, 3, 4, 2, 6], dtype=int32))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find(m.max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 0, 3, 1, 0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = m.tocsc()\n",
    "col_argmax = [B.indices[B.indptr[i] + B.data[B.indptr[i]:B.indptr[i+1]].argmax()] for i in range(len(B.indptr)-1)]\n",
    "col_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.array([\"a\",\"b\",\"c\",\"d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['d', 'b', 'a', 'd', 'b', 'a'], dtype='<U1')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[col_argmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
